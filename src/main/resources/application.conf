wordCountJob {

  input {
    topic: "input"
  }

  output {
    topic: "output"
  }

  stopWords: ["a", "an", "the"]

  windowDuration: 30s

  slideDuration: 5s

  spark {
    "spark.master": "local[*]"
    "spark.app.name": "example-spark-kafka"
  }

  streamingBatchDuration: 5s
  streamingCheckpointDir: ${java.io.tmpdir}/checkpoint/
  streamingShutdownMarker: ${java.io.tmpdir}/stopMarker

  kafkaSource {
    // kafka brokers
    "bootstrap.servers": "localhost:9092"
    // kafka deserializer
    "key.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    // kafka deserializer
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    // kafka group id
    "group.id": "example"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"
  }

  kafkaSink {
    // kafka bootstrap
    "bootstrap.servers": "localhost:9092"
    // kafka key serializer
    "key.serializer": "org.apache.kafka.common.serialization.StringSerializer"
    // kafka key serializer
    "value.serializer": "org.apache.kafka.common.serialization.StringSerializer"
    // ack from all in-sync replicas
    "acks": "all"
    // reduce buffer size from default 32M to 8M
    "buffer.memory": "8388608"
    // block if buffer is full
    "block.on.buffer.full": "true"
    // retry forever
    "retries": "2147483647"
    "retry.backoff.ms": "1500"
  }
}
